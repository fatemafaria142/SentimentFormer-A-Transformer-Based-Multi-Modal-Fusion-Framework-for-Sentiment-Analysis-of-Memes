{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dxc1u_ACS75H"
   },
   "outputs": [],
   "source": [
    "#!unzip /content/drive/MyDrive/MemoSen.zip -d /content/drive/MyDrive/MemoSen_Extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T18:21:45.652484Z",
     "iopub.status.busy": "2025-01-05T18:21:45.652175Z",
     "iopub.status.idle": "2025-01-05T18:21:46.694641Z",
     "shell.execute_reply": "2025-01-05T18:21:46.693838Z",
     "shell.execute_reply.started": "2025-01-05T18:21:45.652440Z"
    },
    "id": "lioQpPJySTUA",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Paths\n",
    "base_dir = '/kaggle/input/memosen/Dataset'\n",
    "image_dir = os.path.join(base_dir, 'Memes')  # Path to the extracted \"Memes\" folder\n",
    "input_excel = os.path.join(base_dir, 'multi-sent.xlsx')  # Path to the Excel file\n",
    "output_csv = os.path.join(\"/kaggle/working/\", 'image_caption_labels.csv')  # Path for the output CSV file\n",
    "\n",
    "# Step 1: Get all image files from the Memes folder\n",
    "image_files = os.listdir(image_dir)\n",
    "\n",
    "# Step 2: Load the Excel file\n",
    "df = pd.read_excel(input_excel)\n",
    "\n",
    "# Step 3: Create a new list to store data for CSV\n",
    "image_data = []\n",
    "\n",
    "# Step 4: Iterate through the Excel data and match image_name with files\n",
    "for index, row in df.iterrows():\n",
    "    image_name = row['image_name']  # Assuming the column name is 'image_name'\n",
    "\n",
    "    # Check if the image exists in the folder\n",
    "    if image_name in image_files:\n",
    "        # Construct the full image path\n",
    "        image_path = os.path.join(image_dir, image_name)\n",
    "\n",
    "        # Extract Captions and Label_Sentiment (adjust column names if necessary)\n",
    "        caption = row['Captions']  # Assuming 'Captions' is the column name for captions\n",
    "        label_sentiment = row['Label_Sentiment']  # Assuming 'Label_Sentiment' is the column name\n",
    "\n",
    "        # Append the row with image path, image name, captions, and sentiment label\n",
    "        image_data.append([image_path, image_name, caption, label_sentiment])\n",
    "\n",
    "# Step 5: Create a DataFrame for the matched data\n",
    "image_df = pd.DataFrame(image_data, columns=['Image_path', 'image_name', 'Captions', 'Label_Sentiment'])\n",
    "\n",
    "# Step 6: Save the DataFrame to a CSV file\n",
    "image_df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"CSV file saved at {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T18:21:46.695911Z",
     "iopub.status.busy": "2025-01-05T18:21:46.695616Z",
     "iopub.status.idle": "2025-01-05T18:21:46.739427Z",
     "shell.execute_reply": "2025-01-05T18:21:46.738700Z",
     "shell.execute_reply.started": "2025-01-05T18:21:46.695883Z"
    },
    "id": "kpDzS6oQYmZg",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to the CSV file (replace this with the actual path if different)\n",
    "csv_file = '/kaggle/working/image_caption_labels.csv'\n",
    "\n",
    "# Step 1: Load the CSV file into a DataFrame\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Step 2: Print the DataFrame to show the contents\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T18:21:47.110739Z",
     "iopub.status.busy": "2025-01-05T18:21:47.110501Z",
     "iopub.status.idle": "2025-01-05T18:21:47.527927Z",
     "shell.execute_reply": "2025-01-05T18:21:47.527028Z",
     "shell.execute_reply.started": "2025-01-05T18:21:47.110719Z"
    },
    "id": "d1ag3hTPZ8Ua",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Step 2: Split the data into train (70%), test (20%), and validation (10%) using stratified splitting\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, stratify=df['Label_Sentiment'], random_state=42)\n",
    "test_df, val_df = train_test_split(temp_df, test_size=1/3, stratify=temp_df['Label_Sentiment'], random_state=42)\n",
    "\n",
    "# Step 3: Save the split data into separate CSV files\n",
    "train_df.to_csv('/kaggle/working/train.csv', index=False)\n",
    "test_df.to_csv('/kaggle/working/test.csv', index=False)\n",
    "val_df.to_csv('/kaggle/working/validation.csv', index=False)\n",
    "\n",
    "# Print the shapes of the resulting datasets for verification\n",
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "print(f\"Validation shape: {val_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T18:21:47.561772Z",
     "iopub.status.busy": "2025-01-05T18:21:47.561558Z",
     "iopub.status.idle": "2025-01-05T18:21:47.767704Z",
     "shell.execute_reply": "2025-01-05T18:21:47.766967Z",
     "shell.execute_reply.started": "2025-01-05T18:21:47.561754Z"
    },
    "id": "bFteyeOZR49Q",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "\n",
    "# Function to remove punctuation (preserve Bangla characters)\n",
    "def remove_punctuation(text):\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "# Function to remove extra whitespace\n",
    "def remove_whitespace(text):\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    return \" \".join(text.split())\n",
    "\n",
    "# Function to remove emojis\n",
    "def remove_emojis(text):\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "# Function to remove URLs\n",
    "def remove_urls(text):\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)\n",
    "\n",
    "# Function to remove HTML tags\n",
    "def remove_html(text):\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    html_pattern = re.compile(r'<.*?>')\n",
    "    return html_pattern.sub(r'', text)\n",
    "\n",
    "# Function to remove special characters (preserve Bangla characters)\n",
    "def remove_special_characters(text):\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    return re.sub(r'[^A-Za-z0-9\\s\\u0980-\\u09FF]', '', text)\n",
    "\n",
    "# Combine all cleaning functions\n",
    "def clean_text(text):\n",
    "    text = remove_urls(text)\n",
    "    text = remove_html(text)\n",
    "    text = remove_emojis(text)\n",
    "    text = remove_punctuation(text)\n",
    "    text = remove_special_characters(text)\n",
    "    text = remove_whitespace(text)\n",
    "    return text\n",
    "\n",
    "# Mapping categories to integers\n",
    "category_mapping = {\n",
    "    'positive': 0,\n",
    "    'negative': 1,\n",
    "    'neutral': 2,\n",
    "}\n",
    "\n",
    "# Paths to the previously saved CSVs\n",
    "csv_paths = {\n",
    "    'Train': '/kaggle/working/train.csv',\n",
    "    'Test': '/kaggle/working/test.csv',\n",
    "    'Validation': '/kaggle/working/validation.csv'\n",
    "}\n",
    "\n",
    "# Output paths for the cleaned CSVs\n",
    "cleaned_output_paths = {\n",
    "    'Train': '/kaggle/working/train_cleaned.csv',\n",
    "    'Test': '/kaggle/working/test_cleaned.csv',\n",
    "    'Validation': '/kaggle/working/validation_cleaned.csv'\n",
    "}\n",
    "\n",
    "# Text columns to clean\n",
    "text_columns = ['Captions', 'Label_Sentiment']\n",
    "\n",
    "# Loop through each dataset\n",
    "for key in csv_paths:\n",
    "    # Load the dataset\n",
    "    df = pd.read_csv(csv_paths[key])\n",
    "\n",
    "    # Apply cleaning to all relevant text columns\n",
    "    for column in text_columns:\n",
    "        df[column] = df[column].astype(str).apply(clean_text)\n",
    "\n",
    "    # Map the 'Label_Sentiment' column to integers\n",
    "    df['Label_Sentiment'] = df['Label_Sentiment'].map(category_mapping)\n",
    "\n",
    "    # Add a 'label' column (same as 'Label_Sentiment' for now)\n",
    "    df['label'] = df['Label_Sentiment']\n",
    "\n",
    "    # Display the cleaned dataframe\n",
    "    print(f\"Cleaned {key} dataframe:\")\n",
    "    print(df.head())\n",
    "\n",
    "    # Save the cleaned dataframe to a new CSV file\n",
    "    df.to_csv(cleaned_output_paths[key], index=False)\n",
    "    print(f\"Cleaned dataframe saved to {cleaned_output_paths[key]}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T18:21:52.791608Z",
     "iopub.status.busy": "2025-01-05T18:21:52.791250Z",
     "iopub.status.idle": "2025-01-05T18:21:52.821188Z",
     "shell.execute_reply": "2025-01-05T18:21:52.820499Z",
     "shell.execute_reply.started": "2025-01-05T18:21:52.791579Z"
    },
    "id": "QeOPOJ4PR49R",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/kaggle/working/train_cleaned.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T18:21:53.465351Z",
     "iopub.status.busy": "2025-01-05T18:21:53.464980Z",
     "iopub.status.idle": "2025-01-05T18:21:53.486829Z",
     "shell.execute_reply": "2025-01-05T18:21:53.486011Z",
     "shell.execute_reply.started": "2025-01-05T18:21:53.465321Z"
    },
    "id": "l4ScAFVBR49R",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('/kaggle/working/test_cleaned.csv')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T18:21:54.233096Z",
     "iopub.status.busy": "2025-01-05T18:21:54.232820Z",
     "iopub.status.idle": "2025-01-05T18:21:54.246656Z",
     "shell.execute_reply": "2025-01-05T18:21:54.245949Z",
     "shell.execute_reply.started": "2025-01-05T18:21:54.233075Z"
    },
    "id": "8oJ-65RkR49S",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "validation_df = pd.read_csv('/kaggle/working/validation_cleaned.csv')\n",
    "validation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T18:21:58.212108Z",
     "iopub.status.busy": "2025-01-05T18:21:58.211824Z",
     "iopub.status.idle": "2025-01-05T18:21:58.232707Z",
     "shell.execute_reply": "2025-01-05T18:21:58.232056Z",
     "shell.execute_reply.started": "2025-01-05T18:21:58.212086Z"
    },
    "id": "PhsxKB71R49S",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from transformers import BertTokenizer, BertModel, AdamW\n",
    "import torchvision.models as models\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T18:21:37.000014Z",
     "iopub.status.busy": "2025-01-05T18:21:36.999723Z",
     "iopub.status.idle": "2025-01-05T18:21:37.003516Z",
     "shell.execute_reply": "2025-01-05T18:21:37.002565Z",
     "shell.execute_reply.started": "2025-01-05T18:21:36.999993Z"
    },
    "id": "yQY6iyNgR49T",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T18:21:40.078215Z",
     "iopub.status.busy": "2025-01-05T18:21:40.077925Z",
     "iopub.status.idle": "2025-01-05T18:21:40.081636Z",
     "shell.execute_reply": "2025-01-05T18:21:40.080860Z",
     "shell.execute_reply.started": "2025-01-05T18:21:40.078193Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# pip show transformers torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T18:20:04.029191Z",
     "iopub.status.busy": "2025-01-05T18:20:04.028850Z",
     "iopub.status.idle": "2025-01-05T18:20:16.656530Z",
     "shell.execute_reply": "2025-01-05T18:20:16.655422Z",
     "shell.execute_reply.started": "2025-01-05T18:20:04.029162Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pip install transformers==4.33.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T18:21:22.452296Z",
     "iopub.status.busy": "2025-01-05T18:21:22.451921Z",
     "iopub.status.idle": "2025-01-05T18:21:25.046391Z",
     "shell.execute_reply": "2025-01-05T18:21:25.045695Z",
     "shell.execute_reply.started": "2025-01-05T18:21:22.452265Z"
    },
    "id": "MtbZ_wnrR49T",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "from transformers import AutoImageProcessor, ViTModel\n",
    "\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\n",
    "model = ViTModel.from_pretrained(\"google/vit-base-patch16-224-in21k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T18:23:03.986438Z",
     "iopub.status.busy": "2025-01-05T18:23:03.986121Z",
     "iopub.status.idle": "2025-01-05T18:23:07.163988Z",
     "shell.execute_reply": "2025-01-05T18:23:07.163322Z",
     "shell.execute_reply.started": "2025-01-05T18:23:03.986416Z"
    },
    "id": "B4DULgGiR49T",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel,AdamW\n",
    "# Initialize BERT tokenizer and model\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('distilbert/distilbert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained(\"distilbert/distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T18:23:08.251725Z",
     "iopub.status.busy": "2025-01-05T18:23:08.251369Z",
     "iopub.status.idle": "2025-01-05T18:23:08.308223Z",
     "shell.execute_reply": "2025-01-05T18:23:08.307185Z",
     "shell.execute_reply.started": "2025-01-05T18:23:08.251698Z"
    },
    "id": "50qxEqr_R49U",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T18:23:11.843986Z",
     "iopub.status.busy": "2025-01-05T18:23:11.843678Z",
     "iopub.status.idle": "2025-01-05T18:23:11.847586Z",
     "shell.execute_reply": "2025-01-05T18:23:11.846752Z",
     "shell.execute_reply.started": "2025-01-05T18:23:11.843960Z"
    },
    "id": "A7-voXolR49U",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Enable device-side assertions\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T18:23:13.026819Z",
     "iopub.status.busy": "2025-01-05T18:23:13.026427Z",
     "iopub.status.idle": "2025-01-05T18:23:13.344166Z",
     "shell.execute_reply": "2025-01-05T18:23:13.343461Z",
     "shell.execute_reply.started": "2025-01-05T18:23:13.026793Z"
    },
    "id": "DeKlqBfTR49U",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T18:23:14.315735Z",
     "iopub.status.busy": "2025-01-05T18:23:14.315373Z",
     "iopub.status.idle": "2025-01-05T18:23:14.442928Z",
     "shell.execute_reply": "2025-01-05T18:23:14.442235Z",
     "shell.execute_reply.started": "2025-01-05T18:23:14.315710Z"
    },
    "id": "obSL_VqNR49U",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "bert_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T18:23:23.844912Z",
     "iopub.status.busy": "2025-01-05T18:23:23.844574Z",
     "iopub.status.idle": "2025-01-05T18:23:23.853126Z",
     "shell.execute_reply": "2025-01-05T18:23:23.852329Z",
     "shell.execute_reply.started": "2025-01-05T18:23:23.844883Z"
    },
    "id": "Bk_ExoLPR49U",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "max_seq_length = 512  # Set your desired maximum sequence length for BERT\n",
    "\n",
    "# Define the pre-processing transformations for images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "class MyMultimodalDataset(Dataset):\n",
    "    def __init__(self, data, transform=None, tokenizer=None, max_seq_length=512):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_seq_length = max_seq_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.data.iloc[idx]['Image_path']\n",
    "        try:\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            if self.transform is not None:\n",
    "                image = self.transform(image)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image at index {idx}: {e}\")\n",
    "            return None, None, None, None\n",
    "\n",
    "        if image is None:\n",
    "            return None, None, None, None\n",
    "\n",
    "        context = self.data.iloc[idx]['Captions']\n",
    "\n",
    "        inputs = self.tokenizer(context, padding='max_length', truncation=True, max_length=self.max_seq_length, return_tensors='pt')\n",
    "        input_ids = inputs['input_ids']\n",
    "        attention_mask = inputs['attention_mask']\n",
    "\n",
    "        label = self.data.iloc[idx]['label']\n",
    "\n",
    "        return image, input_ids, attention_mask, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T18:23:24.940881Z",
     "iopub.status.busy": "2025-01-05T18:23:24.940423Z",
     "iopub.status.idle": "2025-01-05T18:23:24.947392Z",
     "shell.execute_reply": "2025-01-05T18:23:24.946489Z",
     "shell.execute_reply.started": "2025-01-05T18:23:24.940843Z"
    },
    "id": "Q-mX693zR49U",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create custom datasets with MyMultimodalDataset\n",
    "train_dataset = MyMultimodalDataset(train_df, transform=transform, tokenizer=bert_tokenizer, max_seq_length=max_seq_length)\n",
    "test_dataset = MyMultimodalDataset(test_df, transform=transform, tokenizer=bert_tokenizer, max_seq_length=max_seq_length)\n",
    "val_dataset = MyMultimodalDataset(validation_df, transform=transform, tokenizer=bert_tokenizer, max_seq_length=max_seq_length)\n",
    "\n",
    "# Define data loaders\n",
    "batch_size = 1  # Set your desired batch size\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T18:26:00.993704Z",
     "iopub.status.busy": "2025-01-05T18:26:00.993353Z",
     "iopub.status.idle": "2025-01-05T18:33:05.133371Z",
     "shell.execute_reply": "2025-01-05T18:33:05.132529Z",
     "shell.execute_reply.started": "2025-01-05T18:26:00.993674Z"
    },
    "id": "qeXahY7kR49V",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "from transformers import DistilBertModel, AdamW, AutoTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Assuming you have defined your train_loader, val_loader, optimizer, criterion, model, bert_model, etc.\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the regressor model and optimizer\n",
    "regressor = torch.nn.Sequential(\n",
    "    torch.nn.Linear(11548, 512),  # Adjusted input dimension\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(0.5),\n",
    "    torch.nn.Linear(512, 3)  # Adjusted output dimension for your task\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(regressor.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "num_epochs = 40\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_train_loss = 0.0\n",
    "\n",
    "    regressor.train()\n",
    "\n",
    "    # Wrap the training loop with tqdm\n",
    "    for images, texts, attention_masks, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\", ncols=100, leave=False):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        input_ids = texts.squeeze(1).to(device)\n",
    "        attention_mask = attention_masks.squeeze(1).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Extract features from images\n",
    "        with torch.no_grad():\n",
    "            outputs_image = model(pixel_values=images)\n",
    "        img_hidden_states = outputs_image.last_hidden_state\n",
    "        img_feats = img_hidden_states[:, 0, :]\n",
    "\n",
    "        # Extract features from text\n",
    "        outputs_text = bert_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        text_hidden_states = outputs_text.last_hidden_state\n",
    "        text_feats = text_hidden_states[:, 0, :]\n",
    "\n",
    "        # Combine features\n",
    "        combined_feats = torch.cat((img_feats, text_feats), dim=1)\n",
    "\n",
    "        # Forward pass through regressor\n",
    "        predictions = regressor(combined_feats)\n",
    "        loss = criterion(predictions, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_train_loss += loss.item()\n",
    "\n",
    "    epoch_train_loss = running_train_loss / len(train_loader)\n",
    "    train_losses.append(epoch_train_loss)\n",
    "\n",
    "    regressor.eval()\n",
    "\n",
    "    running_val_loss = 0.0\n",
    "\n",
    "    # Wrap the validation loop with tqdm\n",
    "    with torch.no_grad():\n",
    "        for val_images, val_texts, val_attention_masks, val_labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Validation\", ncols=100, leave=False):\n",
    "            val_images = val_images.to(device)\n",
    "            val_labels = val_labels.to(device)\n",
    "\n",
    "            val_input_ids = val_texts.squeeze(1).to(device)\n",
    "            val_attention_mask = val_attention_masks.squeeze(1).to(device)\n",
    "\n",
    "            # Extract features for validation images\n",
    "            outputs_image = model(pixel_values=val_images)\n",
    "            val_img_hidden_states = outputs_image.last_hidden_state\n",
    "            val_img_feats = val_img_hidden_states[:, 0, :]\n",
    "\n",
    "            # Extract features for validation text\n",
    "            outputs_text = bert_model(input_ids=val_input_ids, attention_mask=val_attention_mask)\n",
    "            val_text_hidden_states = outputs_text.last_hidden_state\n",
    "            val_text_feats = val_text_hidden_states[:, 0, :]\n",
    "\n",
    "            # Combine features for validation\n",
    "            val_combined_feats = torch.cat((val_img_feats, val_text_feats), dim=1)\n",
    "\n",
    "            # Forward pass through regressor for validation\n",
    "            val_predictions = regressor(val_combined_feats)\n",
    "            val_loss = criterion(val_predictions, val_labels)\n",
    "\n",
    "            running_val_loss += val_loss.item()\n",
    "\n",
    "    epoch_val_loss = running_val_loss / len(val_loader)\n",
    "    val_losses.append(epoch_val_loss)\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}] - \"\n",
    "          f\"Train Loss: {epoch_train_loss:.4f}, \"\n",
    "          f\"Val Loss: {epoch_val_loss:.4f}\")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Total execution time: {execution_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T18:33:09.332556Z",
     "iopub.status.busy": "2025-01-05T18:33:09.332207Z",
     "iopub.status.idle": "2025-01-05T18:44:39.228990Z",
     "shell.execute_reply": "2025-01-05T18:44:39.228220Z",
     "shell.execute_reply.started": "2025-01-05T18:33:09.332520Z"
    },
    "id": "-LRDxqLbR49V",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Set models to evaluation mode\n",
    "model.eval()\n",
    "bert_model.eval()\n",
    "\n",
    "# Prepare lists to store predicted and true labels\n",
    "predicted_labels = []\n",
    "true_labels = []\n",
    "\n",
    "# Set your device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Test loop\n",
    "start_time = time.time()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for test_images, test_texts, test_attention_masks, test_labels in tqdm(test_loader, desc='Testing', leave=False):\n",
    "        test_images = test_images.to(device)\n",
    "        test_labels = (test_labels).to(device)  # Convert labels from 1-5 to 0-4\n",
    "        test_texts = test_texts.to(device)\n",
    "        test_attention_masks = test_attention_masks.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Extract features from image-based model\n",
    "        test_img_feats = model(test_images)\n",
    "\n",
    "        # Extract features from text-based model (BERT)\n",
    "        test_texts = test_texts.squeeze(1)\n",
    "        test_attention_masks = test_attention_masks.squeeze(1)\n",
    "        test_outputs = bert_model(input_ids=test_texts, attention_mask=test_attention_masks)\n",
    "\n",
    "        # Extract relevant features for concatenation\n",
    "        # Handle tensor manipulation for compatibility\n",
    "        # Reshape test_img_feats if compatible\n",
    "        test_img_feats = test_img_feats[0]  # Access a specific part of the BaseModelOutputWithNoAttention\n",
    "        test_img_feats = test_img_feats.reshape(test_img_feats.shape[0], -1)  # Reshape if compatible\n",
    "\n",
    "        # Extract representations from text-based model\n",
    "        test_text_feats = test_outputs.last_hidden_state[:, 0, :]  # Select appropriate representations\n",
    "\n",
    "        # Combine features early\n",
    "        combined_feats = torch.cat((test_img_feats, test_text_feats), dim=1)\n",
    "\n",
    "        # Classify combined features\n",
    "        combined_classifier = torch.nn.Sequential(\n",
    "            torch.nn.Linear(combined_feats.shape[1], 512).to(device),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.5),\n",
    "            torch.nn.Linear(512, 3).to(device),  # Change the output size to 3 for 3 labels\n",
    "        )\n",
    "\n",
    "        combined_logits = combined_classifier(combined_feats)\n",
    "        test_predictions = torch.nn.functional.softmax(combined_logits, dim=1)\n",
    "        predicted_classes = torch.argmax(test_predictions, dim=1)  # Revert back to labels from 1-5, Add 1 here\n",
    "\n",
    "        predicted_labels.extend(predicted_classes.cpu().numpy())\n",
    "        true_labels.extend(test_labels.cpu().numpy().tolist())\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "# Print or use the predicted labels and true labels as needed\n",
    "print(\"Predicted Labels:\", predicted_labels)\n",
    "print(\"True Labels:\", true_labels)\n",
    "print(f\"Total execution time for testing: {execution_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T19:05:46.655847Z",
     "iopub.status.busy": "2025-01-05T19:05:46.655482Z",
     "iopub.status.idle": "2025-01-05T19:05:46.670236Z",
     "shell.execute_reply": "2025-01-05T19:05:46.669564Z",
     "shell.execute_reply.started": "2025-01-05T19:05:46.655822Z"
    },
    "id": "zTf-Y2mMR49V",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T19:05:47.649968Z",
     "iopub.status.busy": "2025-01-05T19:05:47.649688Z",
     "iopub.status.idle": "2025-01-05T19:05:47.661721Z",
     "shell.execute_reply": "2025-01-05T19:05:47.660821Z",
     "shell.execute_reply.started": "2025-01-05T19:05:47.649945Z"
    },
    "id": "-EhVESdKR49W",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T19:05:48.579364Z",
     "iopub.status.busy": "2025-01-05T19:05:48.579074Z",
     "iopub.status.idle": "2025-01-05T19:05:48.598688Z",
     "shell.execute_reply": "2025-01-05T19:05:48.597844Z",
     "shell.execute_reply.started": "2025-01-05T19:05:48.579342Z"
    },
    "id": "AzkVImq1R49W",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, mean_squared_error, classification_report\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "\n",
    "# Calculate precision, recall, F1-score overall (macro average)\n",
    "precision, recall, f1_score_macro, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='macro')\n",
    "\n",
    "# Calculate weighted precision, recall, and F1-score\n",
    "precision_weighted, recall_weighted, f1_score_weighted, _ = precision_recall_fscore_support(true_labels, predicted_labels, average='weighted')\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse = mean_squared_error(true_labels, predicted_labels)\n",
    "\n",
    "# Calculate Sensitivity (Recall) for each class\n",
    "sensitivity_per_class = recall\n",
    "\n",
    "# Calculate Specificity for each class\n",
    "specificity_per_class = []\n",
    "for i in range(len(conf_matrix)):\n",
    "    tn = np.sum(conf_matrix) - (np.sum(conf_matrix[i, :]) + np.sum(conf_matrix[:, i]) - conf_matrix[i, i])\n",
    "    fp = np.sum(conf_matrix[:, i]) - conf_matrix[i, i]\n",
    "    specificity_per_class.append(tn / (tn + fp))\n",
    "\n",
    "# Print overall calculated metrics\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision (macro): {precision}\")\n",
    "print(f\"Recall (macro): {recall}\")\n",
    "print(f\"F1-Score (macro): {f1_score_macro}\")\n",
    "print(f\"Weighted F1-Score: {f1_score_weighted}\")\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# Print Sensitivity and Specificity for each class\n",
    "print(f\"Sensitivity (Recall) for each class: {sensitivity_per_class}\")\n",
    "print(f\"Specificity for each class: {specificity_per_class}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6429911,
     "sourceId": 10379816,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
